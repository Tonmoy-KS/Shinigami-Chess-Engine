name: "Shinigami-GPT-MAX"

n_embed: 5120

n_layer: 52
n_head: 64
n_kv_heads: 64
block_size: 8192
vocab_size: 50000
dropout: 0.1
untie_weights: true
use_bias: false

# Sliding Window Attention (SWA) for inference
sliding_window_size: 8192

moe:
  num_experts: 4
  num_experts_per_tok: 2

rope_scaling:
  type: "linear"
  factor: 2.0