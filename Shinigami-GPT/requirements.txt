# requirements.txt
torch
tokenizers
transformers
wandb
einops
scipy
pyyaml
numpy
deepspeed
# Triton is for custom GPU kernels on Linux with NVIDIA GPUs
triton
# For Flash Attention 2, install separately for your CUDA version
# pip install flash-attn --no-build-isolation